{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "collapsed": false,
    "id": "89b89f64d8f8053d",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB及以上（推荐使用30系或A10等sm80架构以上的NVIDIA显卡进行尝试）\n",
    "内存：16GB\n",
    "RAM: 2.9 /16 GB\n",
    "GPU RAM: 15.5/16.0 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "collapsed": false,
    "id": "a7bd9a514ed09ea6",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 0. 环境检查\n",
    "首先，先检查代码的运行地址，确保运行地址处于 `finetune_demo` 中。\n",
    "并且，确保已经安装了 `requirements.txt`中的依赖。\n",
    "\n",
    "> 本 demo 中，不需要使用 deepspeed, mpi4py 两个依赖，如果您安装这两个依赖遇到问题，可以不安装这两个依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7703109d1443346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T05:29:22.200365Z",
     "start_time": "2024-04-14T05:29:22.080929Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huangkun/dev/huang-kun/ChatGLM3/finetune_demo\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50e92810011977",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T05:29:23.809255Z",
     "start_time": "2024-04-14T05:29:22.202731Z"
    },
    "cellView": "form",
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "collapsed": false,
    "id": "a1b7a99923349056",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c87410a24d844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T06:23:41.282431Z",
     "start_time": "2024-04-14T05:29:23.810692Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17c87410a24d844f",
    "outputId": "e347fc7d-875e-40c9-c682-3e064100476b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:01<00:00,  6.81it/s]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.0312\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "Map (num_proc=16): 100%|██████| 114599/114599 [00:01<00:00, 92002.84 examples/s]\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 3285.99 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 3025.44 examples/s]\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "{'loss': 4.8312, 'grad_norm': 2.151573419570923, 'learning_rate': 4.9833333333333336e-05, 'epoch': 0.0}\n",
      "{'loss': 4.6012, 'grad_norm': 3.1192708015441895, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 4.4848, 'grad_norm': 2.96707820892334, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1217, 'grad_norm': 3.3529791831970215, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1139, 'grad_norm': 2.6933579444885254, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8697, 'grad_norm': 2.897470712661743, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
      "{'loss': 3.843, 'grad_norm': 2.839460849761963, 'learning_rate': 4.883333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7473, 'grad_norm': 2.8971502780914307, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6348, 'grad_norm': 3.180095672607422, 'learning_rate': 4.85e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7195, 'grad_norm': 3.343719720840454, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6701, 'grad_norm': 3.5705673694610596, 'learning_rate': 4.8166666666666674e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8477, 'grad_norm': 3.825892686843872, 'learning_rate': 4.8e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6148, 'grad_norm': 3.463805913925171, 'learning_rate': 4.7833333333333335e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7326, 'grad_norm': 4.352632522583008, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6844, 'grad_norm': 3.5948591232299805, 'learning_rate': 4.75e-05, 'epoch': 0.01}\n",
      "{'loss': 3.7447, 'grad_norm': 3.8782896995544434, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5754, 'grad_norm': 4.051125526428223, 'learning_rate': 4.716666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5758, 'grad_norm': 4.2962470054626465, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5488, 'grad_norm': 4.722837924957275, 'learning_rate': 4.683333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5773, 'grad_norm': 4.469111919403076, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5529, 'grad_norm': 4.919031143188477, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6488, 'grad_norm': 3.999150276184082, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6141, 'grad_norm': 4.7665324211120605, 'learning_rate': 4.6166666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5098, 'grad_norm': 4.463562965393066, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4742, 'grad_norm': 5.285140037536621, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6025, 'grad_norm': 5.2467241287231445, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5471, 'grad_norm': 5.372445106506348, 'learning_rate': 4.55e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6154, 'grad_norm': 4.519961357116699, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6289, 'grad_norm': 4.7340569496154785, 'learning_rate': 4.516666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5418, 'grad_norm': 5.774693489074707, 'learning_rate': 4.5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4686, 'grad_norm': 5.245972156524658, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6068, 'grad_norm': 5.74026346206665, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4199, 'grad_norm': 5.17270040512085, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4932, 'grad_norm': 5.28303861618042, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5207, 'grad_norm': 5.46736478805542, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5754, 'grad_norm': 5.194791793823242, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3605, 'grad_norm': 4.820713043212891, 'learning_rate': 4.383333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5307, 'grad_norm': 5.109726905822754, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5215, 'grad_norm': 5.224113464355469, 'learning_rate': 4.35e-05, 'epoch': 0.01}\n",
      "{'loss': 3.474, 'grad_norm': 5.6132025718688965, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6922, 'grad_norm': 5.457649230957031, 'learning_rate': 4.316666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4988, 'grad_norm': 4.990589141845703, 'learning_rate': 4.3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6248, 'grad_norm': 5.5776190757751465, 'learning_rate': 4.2833333333333335e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4176, 'grad_norm': 6.555331707000732, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4129, 'grad_norm': 5.972616195678711, 'learning_rate': 4.25e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4281, 'grad_norm': 5.559335708618164, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5324, 'grad_norm': 5.699609756469727, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4438, 'grad_norm': 7.068612575531006, 'learning_rate': 4.2e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4605, 'grad_norm': 5.735531806945801, 'learning_rate': 4.183333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.566, 'grad_norm': 5.89286470413208, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [07:05<40:25,  1.03it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.13s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.81s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  4.54s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.320 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001b[A{'eval_rouge-1': 31.1233, 'eval_rouge-2': 7.070422, 'eval_rouge-l': 24.544010000000004, 'eval_bleu-4': 0.03207262538466599, 'eval_runtime': 26.8568, 'eval_samples_per_second': 1.862, 'eval_steps_per_second': 0.149, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [07:32<40:25,  1.03it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  4.54s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-500\n",
      "loading configuration file /home/huangkun/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "{'loss': 3.3229, 'grad_norm': 5.8071675300598145, 'learning_rate': 4.15e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5467, 'grad_norm': 6.6709885597229, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5814, 'grad_norm': 5.943392753601074, 'learning_rate': 4.116666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4865, 'grad_norm': 5.394510746002197, 'learning_rate': 4.1e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5232, 'grad_norm': 5.3710455894470215, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.6465, 'grad_norm': 5.744597911834717, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4932, 'grad_norm': 5.7500386238098145, 'learning_rate': 4.05e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3723, 'grad_norm': 5.64382266998291, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4238, 'grad_norm': 6.186910629272461, 'learning_rate': 4.016666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4951, 'grad_norm': 6.486273765563965, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
      "{'loss': 3.442, 'grad_norm': 6.114026069641113, 'learning_rate': 3.983333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4594, 'grad_norm': 6.699388027191162, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4484, 'grad_norm': 5.957557678222656, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4576, 'grad_norm': 6.167008399963379, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5352, 'grad_norm': 5.956820487976074, 'learning_rate': 3.9166666666666665e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4848, 'grad_norm': 6.241281986236572, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5438, 'grad_norm': 6.160174369812012, 'learning_rate': 3.883333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3078, 'grad_norm': 6.962684154510498, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3994, 'grad_norm': 6.586282253265381, 'learning_rate': 3.85e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3551, 'grad_norm': 6.345149517059326, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5, 'grad_norm': 7.011747360229492, 'learning_rate': 3.816666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5266, 'grad_norm': 6.758540630340576, 'learning_rate': 3.8e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2479, 'grad_norm': 6.878895282745361, 'learning_rate': 3.7833333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5746, 'grad_norm': 5.787255764007568, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4014, 'grad_norm': 6.428708553314209, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4758, 'grad_norm': 6.173046112060547, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.6215, 'grad_norm': 6.407233238220215, 'learning_rate': 3.7166666666666664e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4729, 'grad_norm': 6.277727127075195, 'learning_rate': 3.7e-05, 'epoch': 0.03}\n",
      "{'loss': 3.326, 'grad_norm': 6.485913276672363, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5488, 'grad_norm': 6.8875956535339355, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2908, 'grad_norm': 6.500704288482666, 'learning_rate': 3.65e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3641, 'grad_norm': 6.4899091720581055, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4643, 'grad_norm': 7.198306560516357, 'learning_rate': 3.6166666666666674e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4078, 'grad_norm': 6.328899383544922, 'learning_rate': 3.6e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5102, 'grad_norm': 6.188563346862793, 'learning_rate': 3.5833333333333335e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5336, 'grad_norm': 6.301794052124023, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2936, 'grad_norm': 7.134566783905029, 'learning_rate': 3.55e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4932, 'grad_norm': 6.761906147003174, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4518, 'grad_norm': 7.330722808837891, 'learning_rate': 3.516666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2666, 'grad_norm': 7.8915510177612305, 'learning_rate': 3.5e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4592, 'grad_norm': 7.843603610992432, 'learning_rate': 3.483333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4176, 'grad_norm': 6.953541278839111, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4611, 'grad_norm': 7.637249946594238, 'learning_rate': 3.45e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5701, 'grad_norm': 7.387135028839111, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3621, 'grad_norm': 6.496081829071045, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4379, 'grad_norm': 7.8605241775512695, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5352, 'grad_norm': 5.969404220581055, 'learning_rate': 3.3833333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3266, 'grad_norm': 7.039161682128906, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4578, 'grad_norm': 7.38445520401001, 'learning_rate': 3.35e-05, 'epoch': 0.03}\n",
      "{'loss': 3.398, 'grad_norm': 7.984394073486328, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [14:35<29:19,  1.14it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.06it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.24s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.487602000000003, 'eval_rouge-2': 6.546197999999999, 'eval_rouge-l': 25.070562, 'eval_bleu-4': 0.03392152739898862, 'eval_runtime': 16.7183, 'eval_samples_per_second': 2.991, 'eval_steps_per_second': 0.239, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [14:51<29:19,  1.14it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.08s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1000\n",
      "loading configuration file /home/huangkun/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "{'loss': 3.4504, 'grad_norm': 6.968799114227295, 'learning_rate': 3.316666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4586, 'grad_norm': 7.400117874145508, 'learning_rate': 3.3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6516, 'grad_norm': 8.17701244354248, 'learning_rate': 3.283333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4002, 'grad_norm': 6.534332752227783, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3906, 'grad_norm': 8.6890869140625, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3533, 'grad_norm': 7.700024604797363, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3891, 'grad_norm': 7.2650909423828125, 'learning_rate': 3.2166666666666665e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4596, 'grad_norm': 7.150012969970703, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5291, 'grad_norm': 7.2002787590026855, 'learning_rate': 3.183333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4678, 'grad_norm': 6.662001609802246, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.04}\n",
      "{'loss': 3.343, 'grad_norm': 6.948875427246094, 'learning_rate': 3.15e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5307, 'grad_norm': 7.951418876647949, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.434, 'grad_norm': 7.326937198638916, 'learning_rate': 3.116666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3627, 'grad_norm': 8.12359619140625, 'learning_rate': 3.1e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3207, 'grad_norm': 7.592392444610596, 'learning_rate': 3.0833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3674, 'grad_norm': 7.160670280456543, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4516, 'grad_norm': 6.714840412139893, 'learning_rate': 3.05e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4752, 'grad_norm': 6.446151256561279, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3566, 'grad_norm': 6.7606048583984375, 'learning_rate': 3.016666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4061, 'grad_norm': 6.483574867248535, 'learning_rate': 3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2443, 'grad_norm': 6.635128498077393, 'learning_rate': 2.9833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3393, 'grad_norm': 7.420434951782227, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3813, 'grad_norm': 7.591280460357666, 'learning_rate': 2.95e-05, 'epoch': 0.04}\n",
      "{'loss': 3.376, 'grad_norm': 7.516971588134766, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4445, 'grad_norm': 6.786386489868164, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2795, 'grad_norm': 7.708741188049316, 'learning_rate': 2.9e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4605, 'grad_norm': 7.171008586883545, 'learning_rate': 2.8833333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3383, 'grad_norm': 7.277571201324463, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3908, 'grad_norm': 7.032768726348877, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4779, 'grad_norm': 7.365076065063477, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4607, 'grad_norm': 7.036080837249756, 'learning_rate': 2.816666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4557, 'grad_norm': 6.82896089553833, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4035, 'grad_norm': 10.490532875061035, 'learning_rate': 2.7833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3047, 'grad_norm': 7.629267692565918, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3457, 'grad_norm': 7.40829610824585, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3043, 'grad_norm': 8.034650802612305, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5189, 'grad_norm': 7.391525745391846, 'learning_rate': 2.716666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3855, 'grad_norm': 7.248948097229004, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3563, 'grad_norm': 7.053771495819092, 'learning_rate': 2.6833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4184, 'grad_norm': 6.581532001495361, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3463, 'grad_norm': 7.559345722198486, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2656, 'grad_norm': 7.798592567443848, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3799, 'grad_norm': 7.718921661376953, 'learning_rate': 2.6166666666666668e-05, 'epoch': 0.05}\n",
      "{'loss': 3.357, 'grad_norm': 7.272255897521973, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2697, 'grad_norm': 7.0086493492126465, 'learning_rate': 2.5833333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3953, 'grad_norm': 7.274815559387207, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4395, 'grad_norm': 9.285033226013184, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2986, 'grad_norm': 6.789473056793213, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4428, 'grad_norm': 7.4674272537231445, 'learning_rate': 2.5166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4594, 'grad_norm': 6.924297332763672, 'learning_rate': 2.5e-05, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [21:52<18:44,  1.33it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.04it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.33s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.942764, 'eval_rouge-2': 6.499836000000001, 'eval_rouge-l': 24.525896000000003, 'eval_bleu-4': 0.031401009417322344, 'eval_runtime': 17.2091, 'eval_samples_per_second': 2.905, 'eval_steps_per_second': 0.232, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [22:09<18:44,  1.33it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.23s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1500\n",
      "loading configuration file /home/huangkun/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "{'loss': 3.343, 'grad_norm': 6.898829936981201, 'learning_rate': 2.4833333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3875, 'grad_norm': 8.46780014038086, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4416, 'grad_norm': 8.174605369567871, 'learning_rate': 2.45e-05, 'epoch': 0.05}\n",
      "{'loss': 3.407, 'grad_norm': 7.069803237915039, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4953, 'grad_norm': 7.44244909286499, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4045, 'grad_norm': 8.533267974853516, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n",
      "{'loss': 3.467, 'grad_norm': 8.028045654296875, 'learning_rate': 2.3833333333333334e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4373, 'grad_norm': 7.4877777099609375, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5096, 'grad_norm': 9.073644638061523, 'learning_rate': 2.35e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3924, 'grad_norm': 7.026591777801514, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3676, 'grad_norm': 7.957065582275391, 'learning_rate': 2.3166666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3713, 'grad_norm': 8.543428421020508, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4707, 'grad_norm': 7.283803462982178, 'learning_rate': 2.2833333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3178, 'grad_norm': 8.18716812133789, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3707, 'grad_norm': 7.5640411376953125, 'learning_rate': 2.25e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3074, 'grad_norm': 7.0555572509765625, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.483, 'grad_norm': 8.699015617370605, 'learning_rate': 2.216666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3736, 'grad_norm': 7.392714977264404, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3775, 'grad_norm': 7.3706793785095215, 'learning_rate': 2.1833333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5156, 'grad_norm': 7.008635997772217, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.46, 'grad_norm': 7.3274335861206055, 'learning_rate': 2.15e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5043, 'grad_norm': 7.419767379760742, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4027, 'grad_norm': 7.4970316886901855, 'learning_rate': 2.116666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3982, 'grad_norm': 7.662409782409668, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4678, 'grad_norm': 7.599307060241699, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4428, 'grad_norm': 7.9735026359558105, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3594, 'grad_norm': 8.737017631530762, 'learning_rate': 2.05e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3498, 'grad_norm': 8.248910903930664, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3918, 'grad_norm': 8.201040267944336, 'learning_rate': 2.0166666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3426, 'grad_norm': 7.808945655822754, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3805, 'grad_norm': 9.003071784973145, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3412, 'grad_norm': 7.856612682342529, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5809, 'grad_norm': 7.877882480621338, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3473, 'grad_norm': 8.58016586303711, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4895, 'grad_norm': 9.020513534545898, 'learning_rate': 1.9166666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3832, 'grad_norm': 7.332064628601074, 'learning_rate': 1.9e-05, 'epoch': 0.06}\n",
      "{'loss': 3.317, 'grad_norm': 8.141484260559082, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3059, 'grad_norm': 7.355489253997803, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4002, 'grad_norm': 7.397273540496826, 'learning_rate': 1.85e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3684, 'grad_norm': 7.859641075134277, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3898, 'grad_norm': 8.046996116638184, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.482, 'grad_norm': 7.5328369140625, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2816, 'grad_norm': 7.820833206176758, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5018, 'grad_norm': 7.6806511878967285, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3611, 'grad_norm': 6.927244186401367, 'learning_rate': 1.75e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2859, 'grad_norm': 8.725592613220215, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.374, 'grad_norm': 7.676575660705566, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2355, 'grad_norm': 7.629798889160156, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.416, 'grad_norm': 7.208089351654053, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4691, 'grad_norm': 7.92787504196167, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [29:11<13:40,  1.22it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.20s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 30.235284000000007, 'eval_rouge-2': 6.5579860000000005, 'eval_rouge-l': 23.016826000000002, 'eval_bleu-4': 0.033918642437805915, 'eval_runtime': 27.3402, 'eval_samples_per_second': 1.829, 'eval_steps_per_second': 0.146, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [29:38<13:40,  1.22it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.09s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2000\n",
      "loading configuration file /home/huangkun/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "{'loss': 3.3877, 'grad_norm': 8.843520164489746, 'learning_rate': 1.65e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4951, 'grad_norm': 7.434727668762207, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5625, 'grad_norm': 8.968830108642578, 'learning_rate': 1.6166666666666665e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4914, 'grad_norm': 8.288307189941406, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.367, 'grad_norm': 8.283402442932129, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3281, 'grad_norm': 7.8872833251953125, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4412, 'grad_norm': 8.18852424621582, 'learning_rate': 1.55e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4164, 'grad_norm': 8.52849292755127, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4396, 'grad_norm': 7.4393181800842285, 'learning_rate': 1.5166666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3559, 'grad_norm': 7.629502296447754, 'learning_rate': 1.5e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2949, 'grad_norm': 7.695777893066406, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5818, 'grad_norm': 7.934854030609131, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2498, 'grad_norm': 7.720219612121582, 'learning_rate': 1.45e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3625, 'grad_norm': 8.307032585144043, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3967, 'grad_norm': 7.42503023147583, 'learning_rate': 1.4166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.518, 'grad_norm': 8.17780590057373, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3953, 'grad_norm': 6.700051784515381, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4146, 'grad_norm': 7.91897439956665, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3549, 'grad_norm': 7.761763095855713, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4385, 'grad_norm': 7.633357524871826, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4545, 'grad_norm': 6.894262313842773, 'learning_rate': 1.3166666666666665e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4203, 'grad_norm': 7.79601526260376, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4166, 'grad_norm': 8.041157722473145, 'learning_rate': 1.2833333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3689, 'grad_norm': 8.433013916015625, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2369, 'grad_norm': 8.460129737854004, 'learning_rate': 1.25e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3652, 'grad_norm': 7.975133895874023, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4303, 'grad_norm': 8.605685234069824, 'learning_rate': 1.2166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4631, 'grad_norm': 7.831568241119385, 'learning_rate': 1.2e-05, 'epoch': 0.08}\n",
      "{'loss': 3.293, 'grad_norm': 8.28944206237793, 'learning_rate': 1.1833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3576, 'grad_norm': 8.468748092651367, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3182, 'grad_norm': 8.452469825744629, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.327, 'grad_norm': 8.464742660522461, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3687, 'grad_norm': 8.924089431762695, 'learning_rate': 1.1166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3625, 'grad_norm': 7.900456428527832, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2697, 'grad_norm': 8.614187240600586, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.374, 'grad_norm': 8.168551445007324, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.352, 'grad_norm': 7.936331748962402, 'learning_rate': 1.05e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4926, 'grad_norm': 8.590060234069824, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2381, 'grad_norm': 8.574942588806152, 'learning_rate': 1.0166666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4598, 'grad_norm': 7.830219268798828, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4537, 'grad_norm': 8.121431350708008, 'learning_rate': 9.833333333333333e-06, 'epoch': 0.08}\n",
      "{'loss': 3.2801, 'grad_norm': 8.067469596862793, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.08}\n",
      "{'loss': 3.3725, 'grad_norm': 7.409722328186035, 'learning_rate': 9.5e-06, 'epoch': 0.08}\n",
      "{'loss': 3.3791, 'grad_norm': 8.01579761505127, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2766, 'grad_norm': 7.831130504608154, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3131, 'grad_norm': 7.749091625213623, 'learning_rate': 9e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2605, 'grad_norm': 8.869626998901367, 'learning_rate': 8.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4354, 'grad_norm': 7.534506320953369, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4746, 'grad_norm': 7.77225923538208, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3949, 'grad_norm': 9.446823120117188, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [36:39<06:55,  1.20it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.23s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.67s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.053973999999997, 'eval_rouge-2': 6.662938, 'eval_rouge-l': 23.469186, 'eval_bleu-4': 0.031090698748729325, 'eval_runtime': 35.9057, 'eval_samples_per_second': 1.393, 'eval_steps_per_second': 0.111, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [37:15<06:55,  1.20it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.97s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2500\n",
      "loading configuration file /home/huangkun/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/huangkun/.pyenv/versions/ChatGLM3/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "{'loss': 3.302, 'grad_norm': 8.510369300842285, 'learning_rate': 8.166666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3396, 'grad_norm': 10.244741439819336, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2475, 'grad_norm': 8.04531192779541, 'learning_rate': 7.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3979, 'grad_norm': 8.193389892578125, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3904, 'grad_norm': 7.776612281799316, 'learning_rate': 7.5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.401, 'grad_norm': 8.406556129455566, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4707, 'grad_norm': 8.11662483215332, 'learning_rate': 7.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4799, 'grad_norm': 8.666301727294922, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3768, 'grad_norm': 8.484960556030273, 'learning_rate': 6.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4752, 'grad_norm': 8.761907577514648, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3584, 'grad_norm': 7.943117618560791, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4262, 'grad_norm': 7.8131585121154785, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.524, 'grad_norm': 7.700938701629639, 'learning_rate': 6.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4453, 'grad_norm': 8.745870590209961, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4088, 'grad_norm': 8.22651195526123, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3525, 'grad_norm': 7.882112979888916, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4098, 'grad_norm': 8.618020057678223, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.268, 'grad_norm': 7.607177734375, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4709, 'grad_norm': 8.70755386352539, 'learning_rate': 5.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4518, 'grad_norm': 8.973214149475098, 'learning_rate': 5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4299, 'grad_norm': 8.365338325500488, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2514, 'grad_norm': 7.706513404846191, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3816, 'grad_norm': 8.05489730834961, 'learning_rate': 4.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3848, 'grad_norm': 8.156044960021973, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4543, 'grad_norm': 8.937336921691895, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3994, 'grad_norm': 8.216346740722656, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3434, 'grad_norm': 8.357073783874512, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2588, 'grad_norm': 8.844202995300293, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2766, 'grad_norm': 8.150716781616211, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2412, 'grad_norm': 7.795025825500488, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4438, 'grad_norm': 7.9636969566345215, 'learning_rate': 3.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.376, 'grad_norm': 7.959707736968994, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3918, 'grad_norm': 7.912870407104492, 'learning_rate': 2.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4424, 'grad_norm': 9.1017484664917, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.407, 'grad_norm': 8.601883888244629, 'learning_rate': 2.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3367, 'grad_norm': 8.473404884338379, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.1}\n",
      "{'loss': 3.376, 'grad_norm': 8.645647048950195, 'learning_rate': 2.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.5102, 'grad_norm': 9.080851554870605, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3043, 'grad_norm': 8.243515014648438, 'learning_rate': 1.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3262, 'grad_norm': 8.967915534973145, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3062, 'grad_norm': 7.933770179748535, 'learning_rate': 1.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2504, 'grad_norm': 7.393082618713379, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3619, 'grad_norm': 8.737655639648438, 'learning_rate': 1.1666666666666668e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2555, 'grad_norm': 8.610069274902344, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3771, 'grad_norm': 8.01081371307373, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.1}\n",
      "{'loss': 3.2113, 'grad_norm': 8.987471580505371, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4443, 'grad_norm': 9.050443649291992, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4281, 'grad_norm': 9.016669273376465, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4754, 'grad_norm': 8.206395149230957, 'learning_rate': 1.6666666666666668e-07, 'epoch': 0.1}\n",
      "{'loss': 3.3689, 'grad_norm': 7.953779697418213, 'learning_rate': 0.0, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [44:18<00:00,  1.25it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.30s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.562194, 'eval_rouge-2': 7.0295440000000005, 'eval_rouge-l': 25.399198, 'eval_bleu-4': 0.03377563069211707, 'eval_runtime': 17.489, 'eval_samples_per_second': 2.859, 'eval_steps_per_second': 0.229, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [44:36<00:00,  1.25it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.15s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-3000\n",
      "loading configuration file /home/huangkun/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 2676.2972, 'train_samples_per_second': 4.484, 'train_steps_per_second': 1.121, 'train_loss': 3.446553385416667, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [44:36<00:00,  1.12it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [08:09<00:00,  7.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# 如果遇到以下报错，需要修改transformers的版本\n",
    "# TypeError: GenerationMixin._extract_past_from_model_output() got an unexpected keyword argument 'standardize_cache_format'\n",
    "# AttributeError: 'str' object has no attribute 'shape'\n",
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python finetune_hf.py  data/AdvertiseGen_fix  /home/huangkun/.cache/modelscope/hub/ZhipuAI/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418f6c5c264601",
   "metadata": {
    "collapsed": false,
    "id": "d9418f6c5c264601",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. 使用微调的数据集进行推理\n",
    "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
    "我们选择最后一轮的微调权重，并使用inference进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5060015c24e97ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T06:23:52.725227Z",
     "start_time": "2024-04-14T06:23:41.284552Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5060015c24e97ae",
    "outputId": "d3f03d0d-46bf-4c74-9b00-dc0160da0e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:01<00:00,  5.32it/s]\n",
      "这款连衣裙采用百褶拼接的网纱设计，让整件连衣裙更加飘逸，轻松展现女性优雅的韵味。拉链套头的设计，方便穿脱，又不会影响美观度。不规则的压褶设计，让裙摆更加飘逸，又增加了层次感，更显得优雅。\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-3000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd83087f096094",
   "metadata": {
    "collapsed": false,
    "id": "18cd83087f096094",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. 总结\n",
    "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
    "在本章节中，你将会学会：\n",
    "+ 如何使用模型进行 Lora 微调\n",
    "+ 微调数据集的准备和对齐\n",
    "+ 使用微调的模型进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d678324-0c9f-4c3b-8c74-d185612ccc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
